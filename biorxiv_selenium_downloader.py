#!/usr/bin/env python3
"""
åŸºäºæˆåŠŸæµ‹è¯•ä»£ç çš„ bioRxiv Selenium ä¸‹è½½å™¨
ä½¿ç”¨ä¸ biorxiv_url_test.py ç›¸åŒçš„é…ç½®æ¥ç¡®ä¿æˆåŠŸä¸‹è½½
"""

import os
import re
import time
import random
import logging
import glob
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class BioRxivSeleniumDownloader:
    def __init__(self, download_dir=None):
        if download_dir is None:
            self.download_dir = os.path.abspath("./temp_biorxiv_downloads")
        else:
            self.download_dir = os.path.abspath(download_dir)

        # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
        os.makedirs(self.download_dir, exist_ok=True)
        self.driver = None
        self.cookie_string = None  # æ·»åŠ  cookie_string å˜é‡

    def parse_cookie_string(self, cookie_string, domain):
        """è§£æCookieå­—ç¬¦ä¸²ä¸ºSeleniumæ ¼å¼"""
        cookies = []
        for item in cookie_string.split(';'):
            if '=' in item:
                name, value = item.strip().split('=', 1)
                cookies.append({
                    "name": name,
                    "value": value,
                    "domain": domain,
                    "path": "/",
                    "secure": False
                })
        return cookies

    def set_cookie_string(self, cookie_string):
        """è®¾ç½® cookie å­—ç¬¦ä¸²"""
        self.cookie_string = cookie_string

    def setup_driver(self):
        """è®¾ç½® Chrome WebDriver - ä½¿ç”¨ä¸æµ‹è¯•ä»£ç ç›¸åŒçš„é…ç½®"""
        try:
            # é…ç½®Chromeé€‰é¡¹ - å®Œå…¨å¤åˆ¶æˆåŠŸçš„é…ç½®
            options = webdriver.ChromeOptions()

            # æ·»åŠ æ— å¤´æ¨¡å¼é…ç½®
            options.add_argument("--headless=new")  # æ–°çš„æ— å¤´æ¨¡å¼ï¼ˆChrome 112+æ¨èï¼‰
            options.add_argument("--disable-gpu")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument("--window-size=1920,1080")

            # ç¦ç”¨è‡ªåŠ¨åŒ–ç‰¹å¾æ£€æµ‹ - å¢å¼ºç‰ˆ
            options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
            options.add_experimental_option("useAutomationExtension", False)
            options.add_argument("--disable-blink-features=AutomationControlled")

            # éšæœºUser-Agentï¼Œé¿å…è¢«è¯†åˆ«ä¸ºçˆ¬è™«
            user_agents = [
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            ]
            options.add_argument(f"user-agent={random.choice(user_agents)}")

            # PDFä¸‹è½½é…ç½®
            prefs = {
                "download.default_directory": self.download_dir,
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "plugins.always_open_pdf_externally": True,
                "profile.default_content_setting_values.automatic_downloads": 1
            }
            options.add_experimental_option('prefs', prefs)

            # è‡ªåŠ¨ä¸‹è½½å’Œåˆå§‹åŒ–WebDriver
            logging.info("æ­£åœ¨åˆå§‹åŒ– ChromeDriver...")
            self.driver = webdriver.Chrome(
                service=Service(ChromeDriverManager().install()),
                options=options
            )

            # è¿›ä¸€æ­¥éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            self.driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
                "source": """
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    })
                """
            })

            return True

        except Exception as e:
            logging.error(f"è®¾ç½® WebDriver å¤±è´¥: {e}")
            return False

    def close_driver(self):
        """å…³é—­ WebDriver"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass
            self.driver = None

    def is_biorxiv_url(self, url):
        """æ£€æŸ¥æ˜¯å¦ä¸º bioRxiv URL"""
        return 'biorxiv.org' in url.lower()

    def extract_paper_id(self, url):
        """ä» URL ä¸­æå–è®ºæ–‡ ID"""
        patterns = [
            r'(\d{4}\.\d{2}\.\d{2}\.\d{6})',  # æ ‡å‡†æ ¼å¼ï¼š2025.09.10.675446
            r'/([^/]+)v\d+',  # ç‰ˆæœ¬å·æ ¼å¼
            r'/([^/]+)$'  # æœ€åä¸€æ®µ
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                paper_id = match.group(1)
                # éªŒè¯æ˜¯å¦ä¸ºæ ‡å‡†æ—¥æœŸæ ¼å¼
                if re.match(r'\d{4}\.\d{2}\.\d{2}\.\d{6}', paper_id):
                    return paper_id

        return None

    def wait_for_download(self, timeout=30):
        """ç­‰å¾…ä¸‹è½½å®Œæˆ"""
        start_time = time.time()

        while time.time() - start_time < timeout:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ PDF æ–‡ä»¶
            pdf_files = glob.glob(os.path.join(self.download_dir, "*.pdf"))

            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨ä¸‹è½½çš„æ–‡ä»¶ï¼ˆ.crdownloadï¼‰
            downloading_files = glob.glob(os.path.join(self.download_dir, "*.crdownload"))

            if pdf_files and not downloading_files:
                # æ‰¾åˆ° PDF æ–‡ä»¶ä¸”æ²¡æœ‰æ­£åœ¨ä¸‹è½½çš„æ–‡ä»¶
                latest_file = max(pdf_files, key=os.path.getctime)
                logging.info(f"ä¸‹è½½å®Œæˆ: {latest_file}")
                return latest_file

            time.sleep(1)

        logging.warning("ä¸‹è½½è¶…æ—¶")
        return None

    def download_biorxiv_pdf(self, url):
        """
        ä¸‹è½½ bioRxiv PDF

        Args:
            url: bioRxiv è®ºæ–‡ URL

        Returns:
            tuple: (success, file_path, message)
        """
        if not self.is_biorxiv_url(url):
            return False, None, "ä¸æ˜¯ bioRxiv URL"

        if not self.setup_driver():
            return False, None, "WebDriver è®¾ç½®å¤±è´¥"

        try:
            # æ¸…ç†ä¸‹è½½ç›®å½•ä¸­çš„æ—§æ–‡ä»¶
            old_files = glob.glob(os.path.join(self.download_dir, "*.pdf"))
            for old_file in old_files:
                try:
                    os.remove(old_file)
                except:
                    pass

            # è®¾ç½® Cookieï¼ˆå¦‚æœæä¾›äº† cookie_stringï¼‰
            if self.cookie_string:
                logging.info("æ­£åœ¨è®¾ç½®Cookie...")

                # å…ˆè®¿é—®ä¸»åŸŸåä»¥è®¾ç½®Cookieä¸Šä¸‹æ–‡
                self.driver.get("https://www.biorxiv.org")
                time.sleep(2)

                # è§£æå¹¶æ·»åŠ Cookie
                cookies = self.parse_cookie_string(self.cookie_string, ".biorxiv.org")

                for cookie in cookies:
                    try:
                        self.driver.add_cookie(cookie)
                        logging.info(f"âœ… å·²æ·»åŠ Cookie: {cookie['name']}")
                    except Exception as e:
                        logging.warning(f"âš ï¸  æ·»åŠ Cookieå¤±è´¥ {cookie['name']}: {e}")

                logging.info(f"ğŸ“Š æ€»å…±å°è¯•æ·»åŠ  {len(cookies)} ä¸ªCookie")

                # éªŒè¯Cookieæ˜¯å¦è®¾ç½®æˆåŠŸ
                current_cookies = self.driver.get_cookies()
                logging.info(f"ğŸ” å½“å‰æµè§ˆå™¨ä¸­æœ‰ {len(current_cookies)} ä¸ªCookie")

            logging.info(f"æ­£åœ¨è®¿é—®: {url}")
            self.driver.get(url)

            # ç­‰å¾…é¡µé¢åŠ è½½ - ä½¿ç”¨ä¸æµ‹è¯•ä»£ç ç›¸åŒçš„éšæœºå»¶æ—¶
            time.sleep(random.uniform(2, 4))
            logging.info("é¡µé¢åŠ è½½å®Œæˆ")

            # ç­‰å¾…ä¸‹è½½å®Œæˆ
            downloaded_file = self.wait_for_download()

            if downloaded_file and os.path.exists(downloaded_file):
                return True, downloaded_file, f"ä¸‹è½½æˆåŠŸ: {os.path.basename(downloaded_file)}"
            else:
                return False, None, "ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶ä¸å­˜åœ¨"

        except Exception as e:
            logging.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False, None, f"ä¸‹è½½å¼‚å¸¸: {e}"
        finally:
            self.close_driver()

    def cleanup_file(self, file_path):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if file_path and os.path.exists(file_path):
                os.remove(file_path)
                logging.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
                return True
        except Exception as e:
            logging.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")
            return False
        return False

def download_biorxiv_with_selenium(url):
    """
    ä½¿ç”¨ Selenium ä¸‹è½½ bioRxiv PDF çš„ä¾¿æ·å‡½æ•°

    Args:
        url: bioRxiv è®ºæ–‡ URL

    Returns:
        tuple: (success, file_path, message)
    """
    downloader = BioRxivSeleniumDownloader()
    return downloader.download_biorxiv_pdf(url)

if __name__ == "__main__":
    # æµ‹è¯•
    test_url = "https://www.biorxiv.org/cgi/reprint/2025.10.09.681381v1??collection"

    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
    downloader = BioRxivSeleniumDownloader()

    # è®¾ç½® cookieï¼ˆå¯é€‰ï¼‰
    cookie_string = "_ga=GA1.1.286901066.1739618871; dsq__u=8tb657p8ldllr; dsq__s=8tb657p8ldllr; _lc2_fpi=28e3293678dc--01jm4nv7gvkp4j5sas17qt968v; cookie-agreed=2; _li_ss=CgA; cf_clearance=JNEmmRvDMaV4eE2T6BlzBjPmx4erKDMM9zOUFJe.aEY-1758710449-1.2.1.1-OCdlkdqtrMbjknFIGT8P7lrqdW8oqCnbgnr4AtXpAaEoydIJ0ihOgIh5USnDU62DirFyRartBHOADHDkUXa3iH7xzAI_IbPCJ_8cg6O1cXH9r1d.mpX6Cdw5qATyFlqZBmOzoTYa3deq0pFwZK2NYK9i8DP9pVvFqZxHECdBiy_e9vyMjWxP_2VHXxq0pQsrzjAl7uKhV8DJkjgcv99zkrtOttvXtQ96savnPYOlqOo; _ga_RZD586MC3Q=GS2.1.s1758793902$o7$g1$t1758794165$j60$l0$h0; _cfuvid=.tjpF4QGjNS.bYKaTJXEaXdtKgMs2EZS1vmwUJvrfxQ-1760244202528-0.0.1.1-604800000; __cf_bm=R2T2yj1BvWtCpWv_k7haN_RuhRrurnBt9Jjn.i7ssxQ-1760322277-1.0.1.1-fXNIfjavwLYg8OtnlQF6QG0aiZ4zVoTYby.9MUNb_TNWWb7yEf8iR9VhHTqGIvfJseyIQTdmlvTNZRcDAOH.ygQdNTqRYY5YU9UJf.1MCIc; SSESS1dd6867f1a1b90340f573dcdef3076bc=ILHNE1wvpfWHqye7T7VzggfTUjfqih5r3virV3nl3UQ"
    downloader.set_cookie_string(cookie_string)

    success, file_path, message = downloader.download_biorxiv_pdf(test_url)

    print(f"ä¸‹è½½ç»“æœ: {success}")
    print(f"æ–‡ä»¶è·¯å¾„: {file_path}")
    print(f"æ¶ˆæ¯: {message}")

    if success and file_path:
        print(f"æ–‡ä»¶å¤§å°: {os.path.getsize(file_path)} bytes")

        # æµ‹è¯•æ¸…ç†
        downloader.cleanup_file(file_path)